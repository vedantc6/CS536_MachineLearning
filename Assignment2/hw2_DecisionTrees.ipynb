{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let ${(X_1, Y_1),(X_2, Y_2), . . . ,(X_m, Y_m)}$ denote a data set, where $X_i$ represents a vector of k (binary) feature values,\n",
    "and $Y_i$ is a corresponding binary class or label that we will need to learn to be able to predict from the X-values.\n",
    "We generate data via the following scheme, defining a distribution for our data set: Let $X = (X_1, X_2, X_3, . . . , X_k)$\n",
    "be a vector of binary values, satisfying the following\n",
    "- $X_1 = 1$ with probability 1/2, $X_1 = 0$ with probability 1/2\n",
    "- For i = 2, . . . , k, $X_i = X_{i−1}$ with probability 3/4, and $X_i = 1 − X_{i−1}$ with probability 1/4.\n",
    "In this way, the first feature value is uniformly random, but every successive feature is strongly correlated with the\n",
    "value of the feature before it. We can then define Y to be a function of X as\n",
    "$$Y = X_1 if w_2X_2 + w_3X_3 + . . . + w_kX_k ≥ 1/2$$\n",
    "$$Y = 1 − X_1 else$$\n",
    "\n",
    "In other words, if the ‘weighted average’ of $X_2, . . . X_k$ tilts high, Y will agree with $X_1$; if the weighted average of\n",
    "$X_2, . . . , X_k$ tilts low, Y will disagree with $X_1$. Take the weights to be defined by $w_i = \\frac{0.9^i}{0.9^2 + 0.9^3 + ... + 0.9^k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. For a given value of k, m, (number of features, number of data points), write a function to generate a training data set based on the above scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(k, m):\n",
    "    X = [[0]*k for i in range(m)]\n",
    "    for i in range(m):\n",
    "        X[i][0] = int(np.random.choice(2, size=1))\n",
    "        for j in range(1, k):\n",
    "            temp = np.random.choice(2, 1, p=[0.25,0.75])\n",
    "            if temp == 1:\n",
    "                X[i][j] = X[i][j-1]\n",
    "            else:\n",
    "                X[i][j] = 1 - X[i][j-1]\n",
    "    return X\n",
    "            \n",
    "def create_weights(k):\n",
    "    div = 0\n",
    "    weight = [0]*(k+1)\n",
    "    for i in range(2, k+1):\n",
    "        div += 0.9**i\n",
    "    for i in range(1, k+1):\n",
    "        weight[i] = (0.9**i)/div\n",
    "        \n",
    "    return weight[1:]\n",
    "    \n",
    "def create_y(X, w, k, m):\n",
    "    y = []\n",
    "    for i in range(m):\n",
    "        val = np.dot(X[i][1:], w[1:].T)\n",
    "#         print(val)\n",
    "        if val < 0.5:\n",
    "            y.append(1 - X[i][0])\n",
    "        else:\n",
    "            y.append(X[i][0])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Given a data set, write a function to fit a decision tree to that data based on splitting the variables by maximizing the information gain. Additionally, return the training error of this tree on the data set, $err_{train}(\\hat{f})$. It may be useful to have a function that takes a data set and a variable, and returns the data set partitioned based on the values of that variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():      \n",
    "    def entropy(self, data):\n",
    "        target = data.keys()[-1]\n",
    "        entropy_y = 0\n",
    "        target_vals = data[target].unique()\n",
    "        \n",
    "        for val in target_vals:\n",
    "            p = data[target].value_counts()[val]/len(data[target])\n",
    "            entropy_y += -p*np.log2(p)\n",
    "        return entropy_y\n",
    "    \n",
    "    def conditional_entropy(self, data, feature):\n",
    "        target = data.keys()[-1]\n",
    "        target_vals = data[target].unique()\n",
    "        feature_vals = data[feature].unique()\n",
    "        cond_entropy_y = 0\n",
    "        \n",
    "        for fval in feature_vals:\n",
    "            entropy = 0\n",
    "            for tval in target_vals:\n",
    "                num = len(data[feature][data[feature] == fval][data[target] == tval])\n",
    "                denom = len(data[feature][data[feature] == fval])\n",
    "                e = num/(denom + epsilon)\n",
    "                entropy += -(e)*np.log2(e + epsilon)\n",
    "            cond_entropy_y += -(denom/len(data))*entropy\n",
    "            \n",
    "        return abs(cond_entropy_y)\n",
    "            \n",
    "    def information_gain_split(self, data):\n",
    "        IG = []\n",
    "        for key in data.keys()[:-1]:\n",
    "            IG.append(self.entropy(data) - self.conditional_entropy(data, key))\n",
    "        \n",
    "        return data.keys()[:-1][np.argmax(IG)]\n",
    "    \n",
    "    def get_subset(self, data, node, value):\n",
    "        return data[data[node] == value].reset_index(drop=True)\n",
    "    \n",
    "    def build_tree(self, data, tree=None):\n",
    "        target = data.keys()[-1]\n",
    "        best_split = self.information_gain_split(data)\n",
    "        feature_vals = data[best_split].unique()\n",
    "        \n",
    "        if tree is None:\n",
    "            tree = {}\n",
    "            tree[best_split] = {}\n",
    "        \n",
    "            \n",
    "        for val in feature_vals:\n",
    "            subset = self.get_subset(data, best_split, val)\n",
    "            target_val, target_counts = np.unique(subset[subset.keys()[-1]], return_counts=True)\n",
    "#             print(target_val, target_counts)\n",
    "            \n",
    "            if len(target_counts) == 1:\n",
    "                tree[best_split][val] = target_val[0]\n",
    "            else:\n",
    "                tree[best_split][val] = self.build_tree(subset)        \n",
    "\n",
    "        return tree\n",
    "    \n",
    "    def predict(self, instance_data, tree):\n",
    "        for node in tree.keys():\n",
    "            value = instance_data[node]\n",
    "            tree = tree[node][value]\n",
    "            prediction = 0\n",
    "            \n",
    "            if type(tree) is dict:\n",
    "                prediction = self.predict(instance_data, tree)\n",
    "            else:\n",
    "                prediction = tree\n",
    "                break\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def fit(self, data, tree):\n",
    "        error = 0\n",
    "        for i in range(len(data)):\n",
    "            prediction = self.predict(data.iloc[i], tree)\n",
    "            if prediction != data.iloc[i][-1]:\n",
    "                error += 1\n",
    "        return error/len(data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a  b  c  d  e  f  g  h  i  j  k\n",
      "0   1  1  0  0  0  0  0  0  0  0  0\n",
      "1   0  0  0  0  0  1  0  0  0  1  1\n",
      "2   1  1  1  0  1  0  0  1  1  1  1\n",
      "3   1  1  1  1  1  1  1  1  0  0  1\n",
      "4   1  0  1  1  1  1  1  0  0  0  1\n",
      "5   1  0  0  1  1  1  1  1  0  0  1\n",
      "6   1  1  1  1  1  1  0  0  1  1  1\n",
      "7   0  0  1  1  1  1  1  1  1  0  0\n",
      "8   0  1  1  1  1  1  1  1  1  1  0\n",
      "9   1  1  0  0  1  1  1  1  1  0  1\n",
      "10  0  1  1  1  0  1  1  0  0  1  0\n",
      "11  0  0  0  1  1  0  0  1  0  0  1\n",
      "12  0  0  0  0  0  0  0  0  0  0  1\n",
      "13  0  1  1  1  1  1  1  1  0  1  0\n",
      "14  0  0  1  0  0  0  0  0  0  0  1\n",
      "15  0  1  1  1  0  0  0  0  0  0  1\n",
      "16  1  0  0  0  1  1  1  1  1  1  1\n",
      "17  0  0  1  1  1  0  0  1  1  1  0\n",
      "18  1  1  1  1  1  1  0  0  1  0  1\n",
      "19  1  1  1  1  1  1  1  1  0  1  1\n",
      "20  0  0  0  0  0  0  0  1  1  0  1\n",
      "21  1  1  1  1  1  0  0  0  0  0  1\n",
      "22  1  1  1  1  0  0  1  1  1  1  1\n",
      "23  1  1  1  1  0  1  1  0  0  0  1\n",
      "24  0  0  0  0  0  0  0  1  1  1  1\n",
      "25  0  0  0  1  1  1  1  1  1  0  0\n",
      "26  1  1  1  1  1  1  1  1  0  1  1\n",
      "27  0  0  1  1  1  1  1  1  1  1  0\n",
      "28  1  0  0  0  0  0  0  0  1  1  0\n",
      "29  1  0  0  0  1  1  1  0  0  0  0\n",
      ".. .. .. .. .. .. .. .. .. .. .. ..\n",
      "70  0  0  0  1  1  1  1  0  1  1  0\n",
      "71  0  0  0  1  1  1  1  1  1  1  0\n",
      "72  1  1  1  1  0  1  0  0  1  0  1\n",
      "73  0  0  0  0  0  0  0  0  0  1  1\n",
      "74  1  1  1  1  1  0  0  0  0  0  1\n",
      "75  1  1  1  1  1  0  0  0  0  0  1\n",
      "76  1  1  1  1  1  1  1  0  1  1  1\n",
      "77  1  0  1  1  1  1  1  1  1  1  1\n",
      "78  0  1  0  0  0  1  1  1  1  1  0\n",
      "79  1  1  1  1  1  1  0  0  1  1  1\n",
      "80  0  0  0  0  0  0  0  0  1  1  1\n",
      "81  0  0  0  1  1  0  0  0  0  0  1\n",
      "82  0  0  0  1  0  1  0  0  0  0  1\n",
      "83  0  1  1  1  1  0  0  0  0  0  0\n",
      "84  0  0  1  0  1  1  1  1  0  0  0\n",
      "85  0  0  0  0  0  0  0  0  0  0  1\n",
      "86  1  1  1  1  1  1  1  0  0  0  1\n",
      "87  1  0  1  1  1  1  1  0  0  0  1\n",
      "88  1  1  1  0  0  0  1  1  1  1  1\n",
      "89  0  0  0  0  1  1  1  1  1  1  0\n",
      "90  0  0  0  0  0  0  0  0  0  0  1\n",
      "91  1  1  0  0  0  1  0  0  0  0  0\n",
      "92  1  1  1  1  1  0  0  0  1  1  1\n",
      "93  1  1  1  1  1  1  1  1  1  1  1\n",
      "94  1  0  0  0  0  0  0  0  1  0  0\n",
      "95  1  1  1  1  1  0  0  0  0  0  1\n",
      "96  1  1  1  1  1  1  1  1  1  0  1\n",
      "97  1  0  0  0  1  0  1  1  1  1  0\n",
      "98  1  1  1  1  0  0  0  1  1  1  1\n",
      "99  1  1  1  1  0  0  0  0  0  0  0\n",
      "\n",
      "[100 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "k, m = 10, 100\n",
    "epsilon = np.finfo(float).eps\n",
    "\n",
    "X = np.asarray(create_data(k, m))\n",
    "w = np.asarray(create_weights(k))\n",
    "y = np.asarray(create_y(X, w, k, m)).reshape((m,1))\n",
    "\n",
    "cols = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "# Training data is an appended version of X and y arrays\n",
    "train_data = pd.DataFrame(np.append(X, y, axis=1), columns=cols[:k+1])\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {0: {'e': {0: {'g': {0: 1, 1: {'j': {0: 1, 1: 0}}}},\n",
      "                 1: {'f': {0: {'c': {0: {'g': {0: 1, 1: 0}}, 1: 0}}, 1: 0}}}},\n",
      "       1: {'c': {0: {'e': {0: 0,\n",
      "                           1: {'b': {0: {'d': {0: {'i': {0: 0,\n",
      "                                                         1: {'f': {0: 0,\n",
      "                                                                   1: 1}}}},\n",
      "                                               1: 1}},\n",
      "                                     1: 1}}}},\n",
      "                 1: {'e': {0: {'i': {0: {'f': {0: 0, 1: 1}}, 1: 1}}, 1: 1}}}}}}\n"
     ]
    }
   ],
   "source": [
    "tree = dt.build_tree(train_data)\n",
    "pprint.pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0\n",
       "b    0\n",
       "c    0\n",
       "d    0\n",
       "e    0\n",
       "f    0\n",
       "g    0\n",
       "h    1\n",
       "i    1\n",
       "j    1\n",
       "k    1\n",
       "Name: 24, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = train_data.iloc[24]\n",
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = dt.predict(instance, tree)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = dt.fit(train_data, tree)\n",
    "error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
